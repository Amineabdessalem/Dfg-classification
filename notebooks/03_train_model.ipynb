{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Train Model\n",
        "\n",
        "This notebook provides an interactive training interface:\n",
        "- Adjust hyperparameters interactively\n",
        "- Visualize training curves in real-time\n",
        "- Try different model configurations\n",
        "- Monitor training progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path().absolute().parent / 'src'))\n",
        "\n",
        "from data_processor import DFGDataset, load_config, load_dfg_mapping\n",
        "from model import DFGClassifier\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "# Enable interactive plots\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"âœ“ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_PATH = '../dfg-classifier/data/processed'  # Change to '../dfg-classifier/data/small' for small dataset\n",
        "CONFIG_PATH = '../config.yaml'\n",
        "DFG_MAPPING_PATH = '../data/dfg_mapping.json'\n",
        "OUTPUT_DIR = '../dfg-classifier/models/experiments'\n",
        "\n",
        "# Load configuration\n",
        "config = load_config(CONFIG_PATH)\n",
        "dfg_mapping = load_dfg_mapping(DFG_MAPPING_PATH)\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"âœ“ Configuration loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "def load_processed_dataset(data_path: str, split: str = 'train'):\n",
        "    \"\"\"Load processed dataset\"\"\"\n",
        "    file_path = os.path.join(data_path, f'{split}.json')\n",
        "    \n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n",
        "    \n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Convert back to tensors\n",
        "    dataset = []\n",
        "    for item in data:\n",
        "        dataset.append({\n",
        "            'input_ids': torch.tensor(item['input_ids']),\n",
        "            'attention_mask': torch.tensor(item['attention_mask']),\n",
        "            'labels': torch.tensor(item['labels']),\n",
        "            'filename': item['filename'],\n",
        "            'title': item['title'],\n",
        "            'abstract': item['abstract'],\n",
        "            'label': item['label']\n",
        "        })\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "print(\"ðŸ“Š Loading datasets...\")\n",
        "train_dataset = load_processed_dataset(DATA_PATH, 'train')\n",
        "val_dataset = load_processed_dataset(DATA_PATH, 'val')\n",
        "test_dataset = load_processed_dataset(DATA_PATH, 'test')\n",
        "\n",
        "print(f\"âœ“ Train: {len(train_dataset)} samples\")\n",
        "print(f\"âœ“ Val: {len(val_dataset)} samples\")\n",
        "print(f\"âœ“ Test: {len(test_dataset)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Adjust these parameters to experiment with different training configurations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters - Adjust these!\n",
        "BATCH_SIZE = 4  # Try 2, 4, 8, 16\n",
        "NUM_EPOCHS = 3  # Try 3, 5, 10\n",
        "LEARNING_RATE = 0.00002  # Try 1e-5, 2e-5, 5e-5\n",
        "DROPOUT_RATE = 0.3  # Try 0.1, 0.3, 0.5\n",
        "FREEZE_BERT = False  # Set True to freeze BERT weights\n",
        "MODEL_NAME = 'allenai/scibert_scivocab_uncased'  # Pre-trained model\n",
        "\n",
        "# Training settings\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PRINT_EVERY = 10  # Print progress every N batches\n",
        "\n",
        "print(\"âš™ï¸  Training Configuration:\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Dropout: {DROPOUT_RATE}\")\n",
        "print(f\"  Freeze BERT: {FREEZE_BERT}\")\n",
        "print(f\"  Device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "def create_data_loader(dataset, batch_size, shuffle=False):\n",
        "    \"\"\"Create PyTorch DataLoader\"\"\"\n",
        "    torch_dataset = DFGDataset(dataset)\n",
        "    return DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=0,  # 0 for notebook compatibility\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "train_loader = create_data_loader(train_dataset, BATCH_SIZE, shuffle=True)\n",
        "val_loader = create_data_loader(val_dataset, BATCH_SIZE, shuffle=False)\n",
        "test_loader = create_data_loader(test_dataset, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"âœ“ Data loaders created\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches: {len(val_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "print(\"ðŸ§  Initializing model...\")\n",
        "\n",
        "num_classes = len(dfg_mapping['level_2']['classes'])\n",
        "\n",
        "model = DFGClassifier(\n",
        "    model_name=MODEL_NAME,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    freeze_bert=FREEZE_BERT,\n",
        "    hierarchical=False,\n",
        "    dfg_mapping=dfg_mapping\n",
        ")\n",
        "\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"âœ“ Model initialized\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Num classes: {num_classes}\")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "print(f\"âœ“ Optimizer: Adam (lr={LEARNING_RATE})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n",
        "\n",
        "Run the training loop and monitor progress in real-time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_f1': []\n",
        "}\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "print(\"ðŸ‹ï¸  Starting training...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "    for batch_idx, batch in enumerate(train_progress):\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask, labels)\n",
        "        loss = outputs['loss']\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update metrics\n",
        "        train_loss += loss.item()\n",
        "        predictions = outputs['predictions']\n",
        "        train_correct += (predictions == labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "        \n",
        "        # Update progress bar\n",
        "        train_progress.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{train_correct/train_total:.4f}'\n",
        "        })\n",
        "    \n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_acc = train_correct / train_total\n",
        "    \n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\")\n",
        "        for batch in val_progress:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            labels = batch['labels'].to(DEVICE)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask, labels)\n",
        "            loss = outputs['loss']\n",
        "            predictions = outputs['predictions']\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            val_correct += (predictions == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "            \n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            val_progress.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{val_correct/val_total:.4f}'\n",
        "            })\n",
        "    \n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "    val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    \n",
        "    # Update history\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = model.state_dict().copy()\n",
        "    \n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f\"\\nðŸ“Š Epoch {epoch+1}/{NUM_EPOCHS} Summary:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    print(f\"  Time: {epoch_time:.2f}s\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nâœ… Training completed!\")\n",
        "print(f\"ðŸŽ¯ Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "# Load best model\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"âœ“ Loaded best model state\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "# Loss curve\n",
        "axes[0].plot(epochs, history['train_loss'], 'o-', label='Train Loss', color='steelblue', linewidth=2)\n",
        "axes[0].plot(epochs, history['val_loss'], 's-', label='Val Loss', color='coral', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Accuracy curve\n",
        "axes[1].plot(epochs, history['train_acc'], 'o-', label='Train Acc', color='steelblue', linewidth=2)\n",
        "axes[1].plot(epochs, history['val_acc'], 's-', label='Val Acc', color='coral', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "axes[1].set_ylim([0, 1])\n",
        "\n",
        "# F1 score curve\n",
        "axes[2].plot(epochs, history['val_f1'], 's-', label='Val F1', color='green', linewidth=2)\n",
        "axes[2].set_xlabel('Epoch', fontsize=12)\n",
        "axes[2].set_ylabel('F1 Score', fontsize=12)\n",
        "axes[2].set_title('Validation F1 Score', fontsize=14, fontweight='bold')\n",
        "axes[2].legend()\n",
        "axes[2].grid(alpha=0.3)\n",
        "axes[2].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nðŸ“ˆ Final Training Metrics:\")\n",
        "print(f\"  Train Loss: {history['train_loss'][-1]:.4f}\")\n",
        "print(f\"  Train Accuracy: {history['train_acc'][-1]:.4f}\")\n",
        "print(f\"  Val Loss: {history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  Val Accuracy: {history['val_acc'][-1]:.4f}\")\n",
        "print(f\"  Val F1: {history['val_f1'][-1]:.4f}\")\n",
        "print(f\"  Best Val Accuracy: {best_val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model\n",
        "\n",
        "Save the trained model for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model and training history\n",
        "model_path = os.path.join(OUTPUT_DIR, 'trained_model.pt')\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "history_path = os.path.join(OUTPUT_DIR, 'training_history.json')\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "print(f\"âœ“ Model saved to: {model_path}\")\n",
        "print(f\"âœ“ Training history saved to: {history_path}\")\n",
        "\n",
        "# Save training config\n",
        "training_config = {\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'num_epochs': NUM_EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'dropout_rate': DROPOUT_RATE,\n",
        "    'freeze_bert': FREEZE_BERT,\n",
        "    'model_name': MODEL_NAME,\n",
        "    'best_val_acc': best_val_acc,\n",
        "    'total_params': total_params,\n",
        "    'trainable_params': trainable_params\n",
        "}\n",
        "\n",
        "config_path = os.path.join(OUTPUT_DIR, 'training_config.json')\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(training_config, f, indent=2)\n",
        "\n",
        "print(f\"âœ“ Training config saved to: {config_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
