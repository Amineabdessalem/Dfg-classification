{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Prepare Dataset\n",
        "\n",
        "This notebook provides an interactive interface for dataset preparation:\n",
        "- Synthetic data generation\n",
        "- Data augmentation with visualization\n",
        "- Adjust augmentation parameters interactively\n",
        "- Class balancing\n",
        "- Train/val/test splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path().absolute().parent / 'src'))\n",
        "\n",
        "from data_processor import DFGDatasetProcessor, load_config, load_dfg_mapping\n",
        "from synthetic_data_generator import SyntheticPaperGenerator, create_training_ready_dataset\n",
        "from data_augmentation import TextAugmenter, DatasetBalancer, create_augmented_dataset\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úì Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG_PATH = '../config.yaml'\n",
        "DFG_MAPPING_PATH = '../data/dfg_mapping.json'\n",
        "OUTPUT_DIR = '../dfg-classifier/data/processed'\n",
        "\n",
        "# Load configuration and DFG mapping\n",
        "config = load_config(CONFIG_PATH)\n",
        "dfg_mapping = load_dfg_mapping(DFG_MAPPING_PATH)\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"  Model: {config.get('model', {}).get('name', 'N/A')}\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Synthetic Data\n",
        "\n",
        "Adjust `SAMPLES_PER_CATEGORY` to control the size of the generated dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters for synthetic data generation\n",
        "SAMPLES_PER_CATEGORY = 50  # Adjust this value (try 50, 100, 200)\n",
        "\n",
        "# Generate synthetic papers\n",
        "print(\"üîÑ Generating synthetic papers...\")\n",
        "generator = SyntheticPaperGenerator(dfg_mapping)\n",
        "synthetic_papers = generator.generate_dataset(\n",
        "    samples_per_category=SAMPLES_PER_CATEGORY,\n",
        "    output_dir=None  # Don't save intermediate results\n",
        ")\n",
        "\n",
        "print(f\"‚úì Generated {len(synthetic_papers)} synthetic papers\")\n",
        "\n",
        "# Show sample\n",
        "if synthetic_papers:\n",
        "    print(\"\\nüìù Sample synthetic paper:\")\n",
        "    sample = synthetic_papers[0]\n",
        "    print(f\"  Category: {sample['category']}\")\n",
        "    print(f\"  Title: {sample['title']}\")\n",
        "    print(f\"  Abstract: {sample['abstract'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize synthetic data distribution\n",
        "if synthetic_papers:\n",
        "    categories = [paper['category'] for paper in synthetic_papers]\n",
        "    category_counts = Counter(categories)\n",
        "    \n",
        "    # Plot distribution\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    labels, counts = zip(*sorted(category_counts.items(), key=lambda x: x[1], reverse=True))\n",
        "    \n",
        "    ax.bar(range(len(labels)), counts, color='steelblue')\n",
        "    ax.set_xticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=9)\n",
        "    ax.set_xlabel('Category', fontsize=12)\n",
        "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
        "    ax.set_title(f'Synthetic Data Distribution ({len(synthetic_papers)} total samples)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"  Categories: {len(category_counts)}\")\n",
        "    print(f\"  Min samples per category: {min(counts)}\")\n",
        "    print(f\"  Max samples per category: {max(counts)}\")\n",
        "    print(f\"  Mean samples per category: {np.mean(counts):.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Process and Tokenize Data\n",
        "\n",
        "Convert synthetic papers to tokenized format for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data processor\n",
        "processor = DFGDatasetProcessor(config, dfg_mapping)\n",
        "\n",
        "# Convert to dataset format\n",
        "print(\"üîÑ Processing and tokenizing data...\")\n",
        "dataset = []\n",
        "for paper in synthetic_papers:\n",
        "    # Combine title and abstract\n",
        "    combined_text = f\"{paper['title']} [SEP] {paper['abstract']}\"\n",
        "    \n",
        "    # Tokenize\n",
        "    tokenized = processor.tokenize_text(combined_text)\n",
        "    \n",
        "    # Get label ID\n",
        "    label_id = processor.label_to_id.get(paper['category'], -1)\n",
        "    \n",
        "    if label_id == -1:\n",
        "        print(f\"‚ö†Ô∏è  Warning: Unknown category: {paper['category']}\")\n",
        "        continue\n",
        "    \n",
        "    dataset.append({\n",
        "        'input_ids': tokenized['input_ids'],\n",
        "        'attention_mask': tokenized['attention_mask'],\n",
        "        'labels': label_id,\n",
        "        'filename': paper['id'],\n",
        "        'title': paper['title'],\n",
        "        'abstract': paper['abstract'],\n",
        "        'label': paper['category'],\n",
        "        'combined_text': combined_text\n",
        "    })\n",
        "\n",
        "print(f\"‚úì Processed {len(dataset)} samples\")\n",
        "print(f\"  Tokenizer: {config.get('model', {}).get('name', 'N/A')}\")\n",
        "print(f\"  Max sequence length: {len(dataset[0]['input_ids']) if dataset else 0} tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Augmentation\n",
        "\n",
        "Adjust augmentation parameters:\n",
        "- `USE_AUGMENTATION`: Enable/disable augmentation\n",
        "- `AUGMENTATION_FACTOR`: Number of augmented samples per original (2 = double the dataset)\n",
        "- `AUGMENTATION_PROB`: Probability of applying augmentation to each sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Augmentation parameters\n",
        "USE_AUGMENTATION = True  # Set to False to skip augmentation\n",
        "AUGMENTATION_FACTOR = 2  # Try 1 (no augmentation), 2 (double), 3 (triple)\n",
        "AUGMENTATION_PROB = 0.3  # Probability of augmenting each sample\n",
        "\n",
        "original_dataset_size = len(dataset)\n",
        "\n",
        "if USE_AUGMENTATION:\n",
        "    print(\"üîÑ Applying data augmentation...\")\n",
        "    \n",
        "    # Initialize augmenter\n",
        "    augmenter = TextAugmenter(\n",
        "        model_name=config.get('model', {}).get('name', 'allenai/scibert_scivocab_uncased'),\n",
        "        augmentation_prob=AUGMENTATION_PROB\n",
        "    )\n",
        "    \n",
        "    # Create augmented dataset\n",
        "    augmented_dataset = create_augmented_dataset(\n",
        "        dataset,\n",
        "        augmenter,\n",
        "        augmentation_factor=AUGMENTATION_FACTOR,\n",
        "        balance_classes=False  # We'll balance separately\n",
        "    )\n",
        "    \n",
        "    dataset = augmented_dataset\n",
        "    \n",
        "    print(f\"‚úì Augmented dataset: {original_dataset_size} ‚Üí {len(dataset)} samples\")\n",
        "    print(f\"  Augmentation factor: {AUGMENTATION_FACTOR}x\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Skipping augmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize augmentation results\n",
        "if USE_AUGMENTATION:\n",
        "    # Compare original vs augmented\n",
        "    original_labels = [item['label'] for item in dataset[:original_dataset_size]]\n",
        "    augmented_labels = [item['label'] for item in dataset]\n",
        "    \n",
        "    original_counts = Counter(original_labels)\n",
        "    augmented_counts = Counter(augmented_labels)\n",
        "    \n",
        "    # Get common labels for comparison\n",
        "    common_labels = sorted(set(original_labels))\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Original distribution\n",
        "    orig_labels_sorted, orig_counts_sorted = zip(*[(l, original_counts[l]) for l in common_labels])\n",
        "    axes[0].bar(range(len(orig_labels_sorted)), orig_counts_sorted, color='steelblue')\n",
        "    axes[0].set_xticks(range(len(orig_labels_sorted)))\n",
        "    axes[0].set_xticklabels(orig_labels_sorted, rotation=45, ha='right', fontsize=8)\n",
        "    axes[0].set_title(f'Original Dataset ({len(original_labels)} samples)', fontsize=13, fontweight='bold')\n",
        "    axes[0].set_ylabel('Count', fontsize=11)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Augmented distribution\n",
        "    aug_labels_sorted, aug_counts_sorted = zip(*[(l, augmented_counts[l]) for l in common_labels])\n",
        "    axes[1].bar(range(len(aug_labels_sorted)), aug_counts_sorted, color='coral')\n",
        "    axes[1].set_xticks(range(len(aug_labels_sorted)))\n",
        "    axes[1].set_xticklabels(aug_labels_sorted, rotation=45, ha='right', fontsize=8)\n",
        "    axes[1].set_title(f'Augmented Dataset ({len(augmented_labels)} samples)', fontsize=13, fontweight='bold')\n",
        "    axes[1].set_ylabel('Count', fontsize=11)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Original: {len(original_labels)} samples, {len(original_counts)} classes\")\n",
        "    print(f\"Augmented: {len(augmented_labels)} samples, {len(augmented_counts)} classes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Class Balancing\n",
        "\n",
        "Balance the dataset to ensure equal representation across classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balancing parameters\n",
        "BALANCE_CLASSES = True  # Set to False to skip balancing\n",
        "BALANCING_STRATEGY = 'oversample'  # Options: 'oversample', 'undersample'\n",
        "\n",
        "if BALANCE_CLASSES:\n",
        "    print(\"üîÑ Balancing classes...\")\n",
        "    \n",
        "    # Show distribution before balancing\n",
        "    before_counts = Counter([item['label'] for item in dataset])\n",
        "    print(f\"  Before: {len(dataset)} samples, {len(before_counts)} classes\")\n",
        "    \n",
        "    # Balance dataset\n",
        "    balancer = DatasetBalancer(strategy=BALANCING_STRATEGY)\n",
        "    balanced_dataset = balancer.balance_dataset(dataset)\n",
        "    dataset = balanced_dataset\n",
        "    \n",
        "    # Show distribution after balancing\n",
        "    after_counts = Counter([item['label'] for item in dataset])\n",
        "    print(f\"  After: {len(dataset)} samples, {len(after_counts)} classes\")\n",
        "    \n",
        "    # Visualize balancing results\n",
        "    common_labels = sorted(set(list(before_counts.keys()) + list(after_counts.keys())))\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    x = np.arange(len(common_labels))\n",
        "    width = 0.35\n",
        "    \n",
        "    before_vals = [before_counts.get(l, 0) for l in common_labels]\n",
        "    after_vals = [after_counts.get(l, 0) for l in common_labels]\n",
        "    \n",
        "    ax.bar(x - width/2, before_vals, width, label='Before Balancing', color='steelblue', alpha=0.7)\n",
        "    ax.bar(x + width/2, after_vals, width, label='After Balancing', color='coral', alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Category', fontsize=12)\n",
        "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
        "    ax.set_title('Class Distribution: Before vs After Balancing', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(common_labels, rotation=45, ha='right', fontsize=8)\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"  Balance improvement: Min samples per class increased from {min(before_vals)} to {min(after_vals)}\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Skipping class balancing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Split Dataset\n",
        "\n",
        "Split the dataset into train/validation/test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "print(\"üîÑ Splitting dataset...\")\n",
        "train_data, val_data, test_data = processor.split_dataset(dataset)\n",
        "\n",
        "print(f\"‚úì Dataset split:\")\n",
        "print(f\"  Train: {len(train_data)} samples ({len(train_data)/len(dataset)*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(val_data)} samples ({len(val_data)/len(dataset)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_data)} samples ({len(test_data)/len(dataset)*100:.1f}%)\")\n",
        "\n",
        "# Visualize split distribution\n",
        "train_labels = Counter([item['label'] for item in train_data])\n",
        "val_labels = Counter([item['label'] for item in val_data])\n",
        "test_labels = Counter([item['label'] for item in test_data])\n",
        "\n",
        "common_labels = sorted(set(list(train_labels.keys()) + list(val_labels.keys()) + list(test_labels.keys())))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "x = np.arange(len(common_labels))\n",
        "width = 0.25\n",
        "\n",
        "train_vals = [train_labels.get(l, 0) for l in common_labels]\n",
        "val_vals = [val_labels.get(l, 0) for l in common_labels]\n",
        "test_vals = [test_labels.get(l, 0) for l in common_labels]\n",
        "\n",
        "ax.bar(x - width, train_vals, width, label='Train', color='steelblue', alpha=0.8)\n",
        "ax.bar(x, val_vals, width, label='Validation', color='orange', alpha=0.8)\n",
        "ax.bar(x + width, test_vals, width, label='Test', color='green', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Category', fontsize=12)\n",
        "ax.set_ylabel('Number of Samples', fontsize=12)\n",
        "ax.set_title('Class Distribution Across Splits', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(common_labels, rotation=45, ha='right', fontsize=8)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Processed Datasets\n",
        "\n",
        "Save the processed datasets to disk for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save datasets\n",
        "print(\"üíæ Saving processed datasets...\")\n",
        "\n",
        "processor.save_processed_dataset(train_data, os.path.join(OUTPUT_DIR, 'train.json'))\n",
        "processor.save_processed_dataset(val_data, os.path.join(OUTPUT_DIR, 'val.json'))\n",
        "processor.save_processed_dataset(test_data, os.path.join(OUTPUT_DIR, 'test.json'))\n",
        "\n",
        "print(f\"‚úì Datasets saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "# Save statistics\n",
        "stats = {\n",
        "    'total_samples': len(dataset),\n",
        "    'train_samples': len(train_data),\n",
        "    'val_samples': len(val_data),\n",
        "    'test_samples': len(test_data),\n",
        "    'num_classes': len(processor.label_to_id),\n",
        "    'samples_per_category': SAMPLES_PER_CATEGORY,\n",
        "    'augmentation_factor': AUGMENTATION_FACTOR if USE_AUGMENTATION else 1,\n",
        "    'balanced': BALANCE_CLASSES,\n",
        "    'class_distribution': dict(train_labels)\n",
        "}\n",
        "\n",
        "stats_file = os.path.join(OUTPUT_DIR, 'dataset_stats.json')\n",
        "with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"‚úì Statistics saved to: {stats_file}\")\n",
        "print(\"\\n‚úÖ Dataset preparation complete!\")\n",
        "print(f\"\\nüìä Final Statistics:\")\n",
        "print(f\"  Total samples: {len(dataset)}\")\n",
        "print(f\"  Train: {len(train_data)}\")\n",
        "print(f\"  Validation: {len(val_data)}\")\n",
        "print(f\"  Test: {len(test_data)}\")\n",
        "print(f\"  Classes: {len(processor.label_to_id)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
